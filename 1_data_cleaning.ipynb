{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7896b8",
   "metadata": {},
   "source": [
    "# **1. Data Cleaning**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca735324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26210, 53)\n",
      "Index(['isbn', 'baf', 'first_version', 'second_version', 'final_version',\n",
      "       'FNF', 'VJ', 'title', 'subtitle', 'publishing_date',\n",
      "       'publishing_date_original', 'title_original', 'language_original',\n",
      "       'series_name', 'series_part', 'series_index', 'edition', 'publisher',\n",
      "       'pages', 'num_pages', 'language_original_name',\n",
      "       'language_original_adjective_neuter', 'language_original_adjective_mf',\n",
      "       'is_translation', 'is_title_original_different', 'translator',\n",
      "       'author_name', 'author_surname', 'pseudonym', 'birthdate', 'birth_year',\n",
      "       'deathdate', 'death_year', 'death_age', 'publishing_age', 'birthplace',\n",
      "       'deathplace', 'nationalities', 'nationality_adjective_mf',\n",
      "       'nationality_adjective_neuters', 'nationality_country_names', 'awards',\n",
      "       'bibliography', 'bibliography_place', 'countries_published',\n",
      "       'known_works', 'product_form', 'debut', 'debut_year', 'author_status',\n",
      "       'title_status', 'professions', 'blurb'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "df = pd.read_csv(config['input_file'], sep=\"\\t\")\n",
    "print(df.shape)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d34563",
   "metadata": {},
   "source": [
    "## **Count Placeholders in Texts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0b79116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    26210.000000\n",
      "mean         0.291034\n",
      "std          1.135419\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          8.000000\n",
      "Name: total_ph, dtype: float64\n",
      "total_ph\n",
      "0    22598\n",
      "1     2730\n",
      "2      304\n",
      "3        4\n",
      "7      314\n",
      "8      260\n",
      "Name: count, dtype: int64\n",
      "total_ph\n",
      "0    86.219000\n",
      "1    10.415872\n",
      "2     1.159863\n",
      "3     0.015261\n",
      "7     1.198016\n",
      "8     0.991988\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "placeholder_re = re.compile(r\"\\[[^\\]]+\\]\")   # anything in [...]\n",
    "\n",
    "def count_placeholders(text: str) -> int:\n",
    "    if pd.isna(text):\n",
    "        return 0\n",
    "    return len(placeholder_re.findall(text))\n",
    "\n",
    "# count per version and a total per row\n",
    "for col in [\"first_version\", \"second_version\", \"final_version\"]:\n",
    "    df[f\"{col}_ph\"] = df[col].map(count_placeholders)\n",
    "\n",
    "df[\"total_ph\"] = df[[f\"{c}_ph\" for c in [\"first_version\",\"second_version\",\"final_version\"]]].sum(axis=1)\n",
    "\n",
    "print(df[\"total_ph\"].describe())  \n",
    "print(df[\"total_ph\"].value_counts().sort_index())\n",
    "\n",
    "# print value counts + percentage \n",
    "print(df[\"total_ph\"].value_counts(normalize=True).sort_index() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7377f",
   "metadata": {},
   "source": [
    "## **Clean Data**\n",
    "- 1. Rename columns\n",
    "- 2. Keep rows with first and final versions present\n",
    "- 3. Drop rows with too many (> 2) placeholders\n",
    "- 4. Keep only rows where three versions are distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d282be30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 26,210 raw rows\n",
      "after dropna (first and final versions present) | removed    261 | remaining  25,949\n",
      "after placeholder filter (≤ 2)           | removed    578 | remaining  25,371\n",
      "after distinct-versions filter           | removed    312 | remaining  25,059\n",
      "Saved 25,059 clean rows → data/clean_books.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'data/clean_books.parquet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import html\n",
    "\n",
    "def clean_raw_data(input_path, output_path, verbose=True):\n",
    "    # Helper\n",
    "    def log(stage: str, before: int, after: int):\n",
    "        if verbose:\n",
    "            removed = before - after\n",
    "            print(f\"{stage:<40} | removed {removed:>6,} | remaining {after:>7,}\")\n",
    "\n",
    "    # Load\n",
    "    df = pd.read_csv(input_path, sep=\"\\t\")\n",
    "    print(f\"Loaded {len(df):,} raw rows\")\n",
    "\n",
    "    # Rename columns\n",
    "    df = df.rename(\n",
    "        columns={\n",
    "            \"first_version\":  \"version1\",\n",
    "            \"second_version\": \"version2\",\n",
    "            \"final_version\":  \"version3\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "    # Keep rows with first and final versions present\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=[\"version1\", \"version3\"])\n",
    "    log(\"after dropna (first and final versions present)\", before, len(df))\n",
    "\n",
    "    # Helpers\n",
    "    def normalise_quotes(text: str) -> str:\n",
    "        return (\n",
    "            text.replace(\"‘\", \"'\").replace(\"’\", \"'\").replace(\"‚\", \"'\")\n",
    "                .replace(\"“\", '\"').replace(\"”\", '\"').replace(\"„\", '\"')\n",
    "        )\n",
    "\n",
    "    def clean_text(text) -> str:\n",
    "        if pd.isna(text):\n",
    "            return \"\"\n",
    "        text = html.unescape(str(text))\n",
    "        text = normalise_quotes(text)\n",
    "        text = re.sub(r\"\\\\n|\\\\t|\\n|\\t\", \" \", text)\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        return text.strip()\n",
    "\n",
    "    # Apply cleaning\n",
    "    for col in [\"version1\", \"version2\", \"version3\"]:\n",
    "        df[col] = df[col].apply(clean_text)\n",
    "\n",
    "    # Drop rows with *too many* placeholders \n",
    "    placeholder = re.compile(r\"\\[[^\\]]+\\]\")\n",
    "\n",
    "    def count_ph(text: str) -> int:\n",
    "        return 0 if pd.isna(text) else len(placeholder.findall(text))\n",
    "\n",
    "    for col in [\"version1\", \"version2\", \"version3\"]:\n",
    "        df[f\"{col}_ph\"] = df[col].map(count_ph)\n",
    "\n",
    "    df[\"total_ph\"] = df[[f\"{c}_ph\" for c in\n",
    "                         (\"version1\", \"version2\", \"version3\")]].sum(axis=1)\n",
    "\n",
    "    before = len(df)\n",
    "    MAX_PH = 2\n",
    "    df = df[df[\"total_ph\"] <= MAX_PH].copy()\n",
    "    log(\"after placeholder filter (≤ 2)\", before, len(df))\n",
    "\n",
    "    # clean-up helper cols\n",
    "    df.drop(columns=[c for c in df.columns\n",
    "                     if c.endswith(\"_ph\") or c == \"total_ph\"],\n",
    "            inplace=True)\n",
    "\n",
    "    # Keep only rows where the three versions are distinct\n",
    "    before = len(df)\n",
    "    df = df[df.apply(\n",
    "        lambda r: len({r[\"version1\"], r[\"version2\"], r[\"version3\"]}) == 3,\n",
    "        axis=1)]\n",
    "    log(\"after distinct-versions filter\", before, len(df))\n",
    "\n",
    "    # Save\n",
    "    df[[\"isbn\", \"title\", \"version1\", \"version2\", \"version3\"]].to_parquet(\n",
    "        output_path, index=False\n",
    "    )\n",
    "    print(f\"Saved {len(df):,} clean rows → {output_path}\")\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# run it\n",
    "clean_raw_data(config[\"input_file\"], config[\"cleaned_file\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
